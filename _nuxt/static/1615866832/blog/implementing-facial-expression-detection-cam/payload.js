__NUXT_JSONP__("/blog/implementing-facial-expression-detection-cam", (function(a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u,v,w,x,y,z,A,B,C,D,E,F,G,H,I,J,K,L,M,N,O,P,Q,R,S,T,U,V,W,X,Y,Z,_,$,aa,ab,ac,ad,ae,af,ag,ah,ai,aj,ak,al,am,an,ao,ap,aq,ar,as,at,au,av,aw,ax,ay,az,aA,aB,aC,aD,aE,aF,aG,aH,aI,aJ,aK,aL,aM,aN,aO,aP,aQ,aR,aS,aT,aU,aV,aW,aX,aY,aZ,a_,a$,ba,bb){return {data:[{blog:{slug:"implementing-facial-expression-detection-cam",description:ax,title:"Implementing Live Facial Expression Detection on Web Browser using open-source Face-Api",subtitle:ax,lead:"The open-source Face-api javascript module provides a real-time facial detection functions that can be used for live facial detection on web",createdAt:"2020-03-15T08:30:27.601Z",updatedAt:"2020-03-15T09:52:47.539Z",cover:{image:"https:\u002F\u002Ffirebasestorage.googleapis.com\u002Fv0\u002Fb\u002Fchivalryytf-e6a04.appspot.com\u002Fo\u002Fblogs%2Fimplementing-facial-expression-detection-cam%2Fface-rec-me-min.png?alt=media&token=7e86e97d-2c9f-4b54-b3ff-af173edbb92f",alt:"Implementing Live Facial Expression Detection on Web Browser using open-source Face-Api cover image",caption:"Photo by Arsen",thumb:"https:\u002F\u002Ffirebasestorage.googleapis.com\u002Fv0\u002Fb\u002Fchivalryytf-e6a04.appspot.com\u002Fo\u002Fblogs%2Fimplementing-facial-expression-detection-cam%2Fface-rec-me-min%20(1).png?alt=media&token=eec3127c-e54f-49b4-b351-8be09e7d2247"},tags:["Face-api","Facial Recognition","Facial Expression","Real-time"],toc:[{id:ay,depth:Q,text:az},{id:aA,depth:Q,text:aB},{id:aC,depth:Q,text:aD},{id:aE,depth:Q,text:aF}],body:{type:"root",children:[{type:b,tag:R,props:{id:ay},children:[{type:b,tag:I,props:{href:"#face-api",ariaHidden:S,tabIndex:T},children:[{type:b,tag:c,props:{className:[U,V]},children:[]}]},{type:a,value:az}]},{type:a,value:i},{type:b,tag:v,props:{},children:[{type:a,value:"Face-api.js is a JavaScript module, built on top of tensorflow.js core. It implements several\nConvolutional Neural Networks (CNNs) to perform face detections and face recognition. It has been\noptimized to work on web and mobile devices."}]},{type:a,value:i},{type:b,tag:v,props:{},children:[{type:a,value:"More examples and full API documentation can be found at\n"},{type:b,tag:I,props:{href:aG,rel:[ac,ad,ae],target:af},children:[{type:a,value:aG}]}]},{type:a,value:i},{type:b,tag:v,props:{},children:[{type:a,value:"This api provides various global neural network instances for different types of facial recognition.\nHowever, in this application, we shall use only three of them."}]},{type:a,value:i},{type:b,tag:v,props:{},children:[{type:b,tag:ag,props:{},children:[{type:a,value:"1. Tiny Face Detector"}]},{type:a,value:"\nTiny Face Detector is an optimized face detector model implemented by face recognition api. The detector computes the locations of each face in an image and will return the bounding boxes together with it's probability for each face. This detector uses depthwise separable convolutions instead of regular convolutions, which makes it\nmuch faster than the other detectors in the api like SSD MobileNet V1. However, it is slightly less accurate."}]},{type:a,value:i},{type:b,tag:v,props:{},children:[{type:a,value:"The Tiny Face Detector has a really good performance of detection, making it much faster,\nsmaller and less resource consuming. This model is highly optimized for mobile and web interfaces.\nThe model is trained on a customized dataset of ~14K labeled using bounding boxes. Moreover,\nthe face model has been trained to predict bounding boxes with complete cover facial feature\npoints, therefore it produces better results on face landmark detections than other models."}]},{type:a,value:i},{type:b,tag:v,props:{},children:[{type:b,tag:ag,props:{},children:[{type:a,value:"2. Face Landmark 68 Net"}]},{type:a,value:"\nThis model is used after the tiny face detector model. It predicts the facial landmarks for each detected face.\nIt employs the ideas of depthwise separable convolutions as well as densely connected blocks. The models have been trained on a dataset of ~35k face images labeled with 68 face landmark points.\nYou can learn more about 68 facial landmarks from this paper.\n"},{type:b,tag:I,props:{href:aH,rel:[ac,ad,ae],target:af},children:[{type:a,value:aH}]},{type:a,value:"\n68 facial landmarks are basically the 68 points on a human face whose relative position can help determine if two faces belong to the same person or not."}]},{type:a,value:i},{type:b,tag:v,props:{},children:[{type:b,tag:ag,props:{},children:[{type:a,value:"3. Face Expression Net"}]},{type:a,value:"\nAs the name suggests, this model is used to categorize the expression of the person's face in one of the seven expressions viz. neutral, happy, sad, angry, fearful, disgusted, surprised. It is lightweight, fast and provides reasonable accuracy. It employs depthwise separable convolutions and densely connected blocks."}]},{type:a,value:i},{type:b,tag:R,props:{id:aA},children:[{type:b,tag:I,props:{href:"#frontend-view---file-element",ariaHidden:S,tabIndex:T},children:[{type:b,tag:c,props:{className:[U,V]},children:[]}]},{type:a,value:aB}]},{type:a,value:i},{type:b,tag:v,props:{},children:[{type:a,value:"Here, we basically build a video frame 720x560 on the center of the screen which will project the camera video output and perform facial recognition on it. The snippet below builds the html page for it."}]},{type:a,value:i},{type:b,tag:aI,props:{className:[aJ]},children:[{type:b,tag:aK,props:{className:[aL,"language-html"]},children:[{type:b,tag:aM,props:{},children:[{type:b,tag:c,props:{className:[d,"doctype"]},children:[{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:"\u003C!"}]},{type:b,tag:c,props:{className:[d,"doctype-tag"]},children:[{type:a,value:"DOCTYPE"}]},{type:a,value:f},{type:b,tag:c,props:{className:[d,aN]},children:[{type:a,value:ah}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:p}]}]},{type:a,value:i},{type:b,tag:c,props:{className:[d,g]},children:[{type:b,tag:c,props:{className:[d,g]},children:[{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:w}]},{type:a,value:ah}]},{type:a,value:f},{type:b,tag:c,props:{className:[d,t]},children:[{type:a,value:"lang"}]},{type:b,tag:c,props:{className:[d,x]},children:[{type:b,tag:c,props:{className:[d,e,y]},children:[{type:a,value:r}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:n}]},{type:a,value:"en"},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:n}]}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:p}]}]},{type:a,value:i},{type:b,tag:c,props:{className:[d,g]},children:[{type:b,tag:c,props:{className:[d,g]},children:[{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:w}]},{type:a,value:aO}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:p}]}]},{type:a,value:q},{type:b,tag:c,props:{className:[d,g]},children:[{type:b,tag:c,props:{className:[d,g]},children:[{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:w}]},{type:a,value:ai}]},{type:a,value:f},{type:b,tag:c,props:{className:[d,t]},children:[{type:a,value:"charset"}]},{type:b,tag:c,props:{className:[d,x]},children:[{type:b,tag:c,props:{className:[d,e,y]},children:[{type:a,value:r}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:n}]},{type:a,value:"UTF-8"},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:n}]}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:p}]}]},{type:a,value:q},{type:b,tag:c,props:{className:[d,g]},children:[{type:b,tag:c,props:{className:[d,g]},children:[{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:w}]},{type:a,value:ai}]},{type:a,value:f},{type:b,tag:c,props:{className:[d,t]},children:[{type:a,value:aN}]},{type:b,tag:c,props:{className:[d,x]},children:[{type:b,tag:c,props:{className:[d,e,y]},children:[{type:a,value:r}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:n}]},{type:a,value:"viewport"},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:n}]}]},{type:a,value:f},{type:b,tag:c,props:{className:[d,t]},children:[{type:a,value:aP}]},{type:b,tag:c,props:{className:[d,x]},children:[{type:b,tag:c,props:{className:[d,e,y]},children:[{type:a,value:r}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:n}]},{type:a,value:"width=device-width, initial-scale=1.0"},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:n}]}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:p}]}]},{type:a,value:q},{type:b,tag:c,props:{className:[d,g]},children:[{type:b,tag:c,props:{className:[d,g]},children:[{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:w}]},{type:a,value:ai}]},{type:a,value:f},{type:b,tag:c,props:{className:[d,t]},children:[{type:a,value:"http-equiv"}]},{type:b,tag:c,props:{className:[d,x]},children:[{type:b,tag:c,props:{className:[d,e,y]},children:[{type:a,value:r}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:n}]},{type:a,value:"X-UA-Compatible"},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:n}]}]},{type:a,value:f},{type:b,tag:c,props:{className:[d,t]},children:[{type:a,value:aP}]},{type:b,tag:c,props:{className:[d,x]},children:[{type:b,tag:c,props:{className:[d,e,y]},children:[{type:a,value:r}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:n}]},{type:a,value:"ie=edge"},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:n}]}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:p}]}]},{type:a,value:q},{type:b,tag:c,props:{className:[d,g]},children:[{type:b,tag:c,props:{className:[d,g]},children:[{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:w}]},{type:a,value:aQ}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:p}]}]},{type:a,value:"Document"},{type:b,tag:c,props:{className:[d,g]},children:[{type:b,tag:c,props:{className:[d,g]},children:[{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:B}]},{type:a,value:aQ}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:p}]}]},{type:a,value:q},{type:b,tag:c,props:{className:[d,J]},children:[{type:a,value:"\u003C!-- getting the open source and the local script module which we will build later --\u003E"}]},{type:a,value:q},{type:b,tag:c,props:{className:[d,g]},children:[{type:b,tag:c,props:{className:[d,g]},children:[{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:w}]},{type:a,value:L}]},{type:a,value:f},{type:b,tag:c,props:{className:[d,t]},children:[{type:a,value:aR}]},{type:a,value:f},{type:b,tag:c,props:{className:[d,t]},children:[{type:a,value:aS}]},{type:b,tag:c,props:{className:[d,x]},children:[{type:b,tag:c,props:{className:[d,e,y]},children:[{type:a,value:r}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:n}]},{type:a,value:"face-api.min.js"},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:n}]}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:p}]}]},{type:b,tag:c,props:{className:[d,L]},children:[]},{type:b,tag:c,props:{className:[d,g]},children:[{type:b,tag:c,props:{className:[d,g]},children:[{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:B}]},{type:a,value:L}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:p}]}]},{type:a,value:q},{type:b,tag:c,props:{className:[d,g]},children:[{type:b,tag:c,props:{className:[d,g]},children:[{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:w}]},{type:a,value:L}]},{type:a,value:f},{type:b,tag:c,props:{className:[d,t]},children:[{type:a,value:aR}]},{type:a,value:f},{type:b,tag:c,props:{className:[d,t]},children:[{type:a,value:aS}]},{type:b,tag:c,props:{className:[d,x]},children:[{type:b,tag:c,props:{className:[d,e,y]},children:[{type:a,value:r}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:n}]},{type:a,value:"script.js"},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:n}]}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:p}]}]},{type:b,tag:c,props:{className:[d,L]},children:[]},{type:b,tag:c,props:{className:[d,g]},children:[{type:b,tag:c,props:{className:[d,g]},children:[{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:B}]},{type:a,value:L}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:p}]}]},{type:a,value:q},{type:b,tag:c,props:{className:[d,J]},children:[{type:a,value:"\u003C!-- styling to make the video frame center and limit it's size --\u003E"}]},{type:a,value:q},{type:b,tag:c,props:{className:[d,g]},children:[{type:b,tag:c,props:{className:[d,g]},children:[{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:w}]},{type:a,value:aj}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:p}]}]},{type:b,tag:c,props:{className:[d,aj]},children:[{type:b,tag:c,props:{className:[d,"language-css"]},children:[{type:a,value:C},{type:b,tag:c,props:{className:[d,aT]},children:[{type:a,value:W}]},{type:a,value:f},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:D}]},{type:a,value:E},{type:b,tag:c,props:{className:[d,F]},children:[{type:a,value:"margin"}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:z}]},{type:a,value:f},{type:b,tag:c,props:{className:[d,K]},children:[{type:a,value:X}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:G}]},{type:a,value:E},{type:b,tag:c,props:{className:[d,F]},children:[{type:a,value:"padding"}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:z}]},{type:a,value:f},{type:b,tag:c,props:{className:[d,K]},children:[{type:a,value:X}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:G}]},{type:a,value:E},{type:b,tag:c,props:{className:[d,F]},children:[{type:a,value:Y}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:z}]},{type:a,value:f},{type:b,tag:c,props:{className:[d,K]},children:[{type:a,value:ak}]},{type:b,tag:c,props:{className:[d,aU]},children:[{type:a,value:"vw"}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:G}]},{type:a,value:E},{type:b,tag:c,props:{className:[d,F]},children:[{type:a,value:Z}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:z}]},{type:a,value:f},{type:b,tag:c,props:{className:[d,K]},children:[{type:a,value:ak}]},{type:b,tag:c,props:{className:[d,aU]},children:[{type:a,value:"vh"}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:G}]},{type:a,value:E},{type:b,tag:c,props:{className:[d,F]},children:[{type:a,value:"display"}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:z}]},{type:a,value:" flex"},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:G}]},{type:a,value:E},{type:b,tag:c,props:{className:[d,F]},children:[{type:a,value:"justify-content"}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:z}]},{type:a,value:aV},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:G}]},{type:a,value:E},{type:b,tag:c,props:{className:[d,F]},children:[{type:a,value:"align-items"}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:z}]},{type:a,value:aV},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:G}]},{type:a,value:C},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:H}]},{type:a,value:"\n\n    "},{type:b,tag:c,props:{className:[d,aT]},children:[{type:a,value:M}]},{type:a,value:f},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:D}]},{type:a,value:E},{type:b,tag:c,props:{className:[d,F]},children:[{type:a,value:"position"}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:z}]},{type:a,value:" absolute"},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:G}]},{type:a,value:C},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:H}]},{type:a,value:q}]}]},{type:b,tag:c,props:{className:[d,g]},children:[{type:b,tag:c,props:{className:[d,g]},children:[{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:B}]},{type:a,value:aj}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:p}]}]},{type:a,value:i},{type:b,tag:c,props:{className:[d,g]},children:[{type:b,tag:c,props:{className:[d,g]},children:[{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:B}]},{type:a,value:aO}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:p}]}]},{type:a,value:i},{type:b,tag:c,props:{className:[d,g]},children:[{type:b,tag:c,props:{className:[d,g]},children:[{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:w}]},{type:a,value:W}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:p}]}]},{type:a,value:i},{type:b,tag:c,props:{className:[d,J]},children:[{type:a,value:"\u003C!-- Adding the video frame with 560p dimension. Autoplay to start without hitting any button and muted because we don't need any sound  --\u003E"}]},{type:a,value:q},{type:b,tag:c,props:{className:[d,g]},children:[{type:b,tag:c,props:{className:[d,g]},children:[{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:w}]},{type:a,value:O}]},{type:a,value:f},{type:b,tag:c,props:{className:[d,t]},children:[{type:a,value:"id"}]},{type:b,tag:c,props:{className:[d,x]},children:[{type:b,tag:c,props:{className:[d,e,y]},children:[{type:a,value:r}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:n}]},{type:a,value:O},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:n}]}]},{type:a,value:f},{type:b,tag:c,props:{className:[d,t]},children:[{type:a,value:Y}]},{type:b,tag:c,props:{className:[d,x]},children:[{type:b,tag:c,props:{className:[d,e,y]},children:[{type:a,value:r}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:n}]},{type:a,value:"720"},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:n}]}]},{type:a,value:f},{type:b,tag:c,props:{className:[d,t]},children:[{type:a,value:Z}]},{type:b,tag:c,props:{className:[d,x]},children:[{type:b,tag:c,props:{className:[d,e,y]},children:[{type:a,value:r}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:n}]},{type:a,value:"560"},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:n}]}]},{type:a,value:f},{type:b,tag:c,props:{className:[d,t]},children:[{type:a,value:"autoplay"}]},{type:a,value:f},{type:b,tag:c,props:{className:[d,t]},children:[{type:a,value:"muted"}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:p}]}]},{type:b,tag:c,props:{className:[d,g]},children:[{type:b,tag:c,props:{className:[d,g]},children:[{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:B}]},{type:a,value:O}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:p}]}]},{type:a,value:i},{type:b,tag:c,props:{className:[d,g]},children:[{type:b,tag:c,props:{className:[d,g]},children:[{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:B}]},{type:a,value:W}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:p}]}]},{type:a,value:i},{type:b,tag:c,props:{className:[d,g]},children:[{type:b,tag:c,props:{className:[d,g]},children:[{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:B}]},{type:a,value:ah}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:p}]}]},{type:a,value:i}]}]}]},{type:a,value:i},{type:b,tag:R,props:{id:aC},children:[{type:b,tag:I,props:{href:"#application---the-script",ariaHidden:S,tabIndex:T},children:[{type:b,tag:c,props:{className:[U,V]},children:[]}]},{type:a,value:aD}]},{type:a,value:i},{type:b,tag:v,props:{},children:[{type:a,value:"The functions of the script are as follows:"}]},{type:a,value:i},{type:b,tag:"ol",props:{},children:[{type:a,value:i},{type:b,tag:al,props:{},children:[{type:a,value:"Load the required face-api models"}]},{type:a,value:i},{type:b,tag:al,props:{},children:[{type:a,value:"Capture the live camera recording and render it on the video frame we built earlier on the html page"}]},{type:a,value:i},{type:b,tag:al,props:{},children:[{type:a,value:"Get the video from the video frame, convert it to canvas, then draw the result of face detection, facial landmarks and facial expression on top of it every 0.1 second."}]},{type:a,value:i}]},{type:a,value:i},{type:b,tag:v,props:{},children:[{type:a,value:"The snippet below demonstrates the use of this technique."}]},{type:a,value:i},{type:b,tag:aI,props:{className:[aJ]},children:[{type:b,tag:aK,props:{className:[aL,"language-javascript"]},children:[{type:b,tag:aM,props:{},children:[{type:b,tag:c,props:{className:[d,J]},children:[{type:a,value:"\u002F\u002Fget the video tag"}]},{type:a,value:i},{type:b,tag:c,props:{className:[d,A]},children:[{type:a,value:P}]},{type:a,value:" video "},{type:b,tag:c,props:{className:[d,u]},children:[{type:a,value:r}]},{type:a,value:f},{type:b,tag:c,props:{className:[d,am,an]},children:[{type:a,value:aW}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:h}]},{type:b,tag:c,props:{className:[d,o,m,j]},children:[{type:a,value:"getElementById"}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:k}]},{type:b,tag:c,props:{className:[d,N]},children:[{type:a,value:"'video'"}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:l}]},{type:a,value:ao},{type:b,tag:c,props:{className:[d,J]},children:[{type:a,value:"\u002F\u002Fget all the required model and then calling start video function"}]},{type:a,value:i},{type:b,tag:c,props:{className:[d,"known-class-name",ap]},children:[{type:a,value:"Promise"}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:h}]},{type:b,tag:c,props:{className:[d,o,m,j]},children:[{type:a,value:"all"}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:k}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:"["}]},{type:a,value:_},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:h}]},{type:b,tag:c,props:{className:[d,j]},children:[{type:a,value:aq}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:h}]},{type:b,tag:c,props:{className:[d,j]},children:[{type:a,value:"tinyFaceDetector"}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:h}]},{type:b,tag:c,props:{className:[d,o,m,j]},children:[{type:a,value:ar}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:k}]},{type:b,tag:c,props:{className:[d,N]},children:[{type:a,value:as}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:l}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:s}]},{type:a,value:_},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:h}]},{type:b,tag:c,props:{className:[d,j]},children:[{type:a,value:aq}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:h}]},{type:b,tag:c,props:{className:[d,j]},children:[{type:a,value:"faceLandmark68Net"}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:h}]},{type:b,tag:c,props:{className:[d,o,m,j]},children:[{type:a,value:ar}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:k}]},{type:b,tag:c,props:{className:[d,N]},children:[{type:a,value:as}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:l}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:s}]},{type:a,value:_},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:h}]},{type:b,tag:c,props:{className:[d,j]},children:[{type:a,value:aq}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:h}]},{type:b,tag:c,props:{className:[d,j]},children:[{type:a,value:"faceExpressionNet"}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:h}]},{type:b,tag:c,props:{className:[d,o,m,j]},children:[{type:a,value:ar}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:k}]},{type:b,tag:c,props:{className:[d,N]},children:[{type:a,value:as}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:l}]},{type:a,value:i},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:"]"}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:l}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:h}]},{type:b,tag:c,props:{className:[d,o,m,j]},children:[{type:a,value:"then"}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:k}]},{type:a,value:aX},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:l}]},{type:a,value:ao},{type:b,tag:c,props:{className:[d,J]},children:[{type:a,value:"\u002F\u002Fthis gets the camera input and renders it on our 720x560 video frame we built earlier"}]},{type:a,value:i},{type:b,tag:c,props:{className:[d,A]},children:[{type:a,value:m}]},{type:a,value:f},{type:b,tag:c,props:{className:[d,m]},children:[{type:a,value:aX}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:k}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:l}]},{type:a,value:f},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:D}]},{type:a,value:q},{type:b,tag:c,props:{className:[d,am,an]},children:[{type:a,value:"navigator"}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:h}]},{type:b,tag:c,props:{className:[d,o,m,j]},children:[{type:a,value:"getUserMedia"}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:k}]},{type:a,value:C},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:D}]},{type:a,value:$},{type:b,tag:c,props:{className:[d,u]},children:[{type:a,value:z}]},{type:a,value:f},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:D}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:H}]},{type:a,value:f},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:H}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:s}]},{type:a,value:C},{type:b,tag:c,props:{className:[d,aY]},children:[{type:a,value:"stream"}]},{type:a,value:f},{type:b,tag:c,props:{className:[d,aa,u]},children:[{type:a,value:ab}]},{type:a,value:$},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:h}]},{type:b,tag:c,props:{className:[d,j]},children:[{type:a,value:"srcObject"}]},{type:a,value:f},{type:b,tag:c,props:{className:[d,u]},children:[{type:a,value:r}]},{type:a,value:" stream"},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:s}]},{type:a,value:C},{type:b,tag:c,props:{className:[d,aY]},children:[{type:a,value:aZ}]},{type:a,value:f},{type:b,tag:c,props:{className:[d,aa,u]},children:[{type:a,value:ab}]},{type:a,value:f},{type:b,tag:c,props:{className:[d,a_,ap]},children:[{type:a,value:a_}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:h}]},{type:b,tag:c,props:{className:[d,o,m,j]},children:[{type:a,value:"error"}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:k}]},{type:a,value:aZ},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:l}]},{type:a,value:q},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:l}]},{type:a,value:i},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:H}]},{type:a,value:ao},{type:b,tag:c,props:{className:[d,J]},children:[{type:a,value:"\u002F\u002Fonce the video starts playing, captures video frames and draws facial boxes, facial landmarks and facial expression on top of the detected faces in the frame every 0.1 second"}]},{type:a,value:"\n\nvideo"},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:h}]},{type:b,tag:c,props:{className:[d,o,m,j]},children:[{type:a,value:"addEventListener"}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:k}]},{type:b,tag:c,props:{className:[d,N]},children:[{type:a,value:"'play'"}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:s}]},{type:a,value:f},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:k}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:l}]},{type:a,value:f},{type:b,tag:c,props:{className:[d,aa,u]},children:[{type:a,value:ab}]},{type:a,value:f},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:D}]},{type:a,value:q},{type:b,tag:c,props:{className:[d,A]},children:[{type:a,value:P}]},{type:a,value:" canvas "},{type:b,tag:c,props:{className:[d,u]},children:[{type:a,value:r}]},{type:a,value:at},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:h}]},{type:b,tag:c,props:{className:[d,o,m,j]},children:[{type:a,value:"createCanvasFromMedia"}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:k}]},{type:a,value:O},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:l}]},{type:a,value:q},{type:b,tag:c,props:{className:[d,am,an]},children:[{type:a,value:aW}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:h}]},{type:b,tag:c,props:{className:[d,j]},children:[{type:a,value:W}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:h}]},{type:b,tag:c,props:{className:[d,o,m,j]},children:[{type:a,value:"append"}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:k}]},{type:a,value:M},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:l}]},{type:a,value:q},{type:b,tag:c,props:{className:[d,A]},children:[{type:a,value:P}]},{type:a,value:" displaySize "},{type:b,tag:c,props:{className:[d,u]},children:[{type:a,value:r}]},{type:a,value:f},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:D}]},{type:a,value:" width"},{type:b,tag:c,props:{className:[d,u]},children:[{type:a,value:z}]},{type:a,value:$},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:h}]},{type:b,tag:c,props:{className:[d,j]},children:[{type:a,value:Y}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:s}]},{type:a,value:" height"},{type:b,tag:c,props:{className:[d,u]},children:[{type:a,value:z}]},{type:a,value:$},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:h}]},{type:b,tag:c,props:{className:[d,j]},children:[{type:a,value:Z}]},{type:a,value:f},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:H}]},{type:a,value:_},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:h}]},{type:b,tag:c,props:{className:[d,o,m,j]},children:[{type:a,value:"matchDimensions"}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:k}]},{type:a,value:M},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:s}]},{type:a,value:a$},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:l}]},{type:a,value:q},{type:b,tag:c,props:{className:[d,m]},children:[{type:a,value:"setInterval"}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:k}]},{type:b,tag:c,props:{className:[d,A]},children:[{type:a,value:"async"}]},{type:a,value:f},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:k}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:l}]},{type:a,value:f},{type:b,tag:c,props:{className:[d,aa,u]},children:[{type:a,value:ab}]},{type:a,value:f},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:D}]},{type:a,value:C},{type:b,tag:c,props:{className:[d,A]},children:[{type:a,value:P}]},{type:a,value:" detections "},{type:b,tag:c,props:{className:[d,u]},children:[{type:a,value:r}]},{type:a,value:f},{type:b,tag:c,props:{className:[d,A,"control-flow"]},children:[{type:a,value:"await"}]},{type:a,value:at},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:h}]},{type:b,tag:c,props:{className:[d,o,m,j]},children:[{type:a,value:"detectAllFaces"}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:k}]},{type:a,value:O},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:s}]},{type:a,value:f},{type:b,tag:c,props:{className:[d,A]},children:[{type:a,value:"new"}]},{type:a,value:f},{type:b,tag:c,props:{className:[d,ap]},children:[{type:a,value:"faceapi"},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:h}]},{type:a,value:"TinyFaceDetectorOptions"}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:k}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:l}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:l}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:h}]},{type:b,tag:c,props:{className:[d,o,m,j]},children:[{type:a,value:"withFaceLandmarks"}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:k}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:l}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:h}]},{type:b,tag:c,props:{className:[d,o,m,j]},children:[{type:a,value:"withFaceExpressions"}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:k}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:l}]},{type:a,value:C},{type:b,tag:c,props:{className:[d,A]},children:[{type:a,value:P}]},{type:a,value:" resizedDetections "},{type:b,tag:c,props:{className:[d,u]},children:[{type:a,value:r}]},{type:a,value:at},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:h}]},{type:b,tag:c,props:{className:[d,o,m,j]},children:[{type:a,value:"resizeResults"}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:k}]},{type:a,value:"detections"},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:s}]},{type:a,value:a$},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:l}]},{type:a,value:"\n    canvas"},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:h}]},{type:b,tag:c,props:{className:[d,o,m,j]},children:[{type:a,value:"getContext"}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:k}]},{type:b,tag:c,props:{className:[d,N]},children:[{type:a,value:"'2d'"}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:l}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:h}]},{type:b,tag:c,props:{className:[d,o,m,j]},children:[{type:a,value:"clearRect"}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:k}]},{type:b,tag:c,props:{className:[d,K]},children:[{type:a,value:X}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:s}]},{type:a,value:f},{type:b,tag:c,props:{className:[d,K]},children:[{type:a,value:X}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:s}]},{type:a,value:ba},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:h}]},{type:b,tag:c,props:{className:[d,j]},children:[{type:a,value:Y}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:s}]},{type:a,value:ba},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:h}]},{type:b,tag:c,props:{className:[d,j]},children:[{type:a,value:Z}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:l}]},{type:a,value:au},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:h}]},{type:b,tag:c,props:{className:[d,j]},children:[{type:a,value:av}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:h}]},{type:b,tag:c,props:{className:[d,o,m,j]},children:[{type:a,value:"drawDetections"}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:k}]},{type:a,value:M},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:s}]},{type:a,value:aw},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:l}]},{type:a,value:au},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:h}]},{type:b,tag:c,props:{className:[d,j]},children:[{type:a,value:av}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:h}]},{type:b,tag:c,props:{className:[d,o,m,j]},children:[{type:a,value:"drawFaceLandmarks"}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:k}]},{type:a,value:M},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:s}]},{type:a,value:aw},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:l}]},{type:a,value:au},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:h}]},{type:b,tag:c,props:{className:[d,j]},children:[{type:a,value:av}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:h}]},{type:b,tag:c,props:{className:[d,o,m,j]},children:[{type:a,value:"drawFaceExpressions"}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:k}]},{type:a,value:M},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:s}]},{type:a,value:aw},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:l}]},{type:a,value:q},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:H}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:s}]},{type:a,value:f},{type:b,tag:c,props:{className:[d,K]},children:[{type:a,value:ak}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:l}]},{type:a,value:i},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:H}]},{type:b,tag:c,props:{className:[d,e]},children:[{type:a,value:l}]},{type:a,value:i}]}]}]},{type:a,value:i},{type:b,tag:R,props:{id:aE},children:[{type:b,tag:I,props:{href:"#live-demonstration",ariaHidden:S,tabIndex:T},children:[{type:b,tag:c,props:{className:[U,V]},children:[]}]},{type:a,value:aF}]},{type:a,value:i},{type:b,tag:v,props:{},children:[{type:a,value:"You can follow this link to get the live demonstration of the facial expression detection cam, we built here.\n"},{type:b,tag:I,props:{href:bb,rel:[ac,ad,ae],target:af},children:[{type:a,value:bb}]}]}]},dir:"\u002Fblog",path:"\u002Fblog\u002Fimplementing-facial-expression-detection-cam",extension:".md"},prev:{slug:"optimizing-and-resizing-images-using-canvas-api",title:"Resizing and Optimizing Images Using Canvas API",createdAt:"2020-03-06T08:30:27.601Z"},next:null}],fetch:[],mutations:void 0}}("text","element","span","token","punctuation"," ","tag",".","\n","property-access","(",")","function","\"","method","\u003E","\n  ","=",",","attr-name","operator","p","\u003C","attr-value","attr-equals",":","keyword","\u003C\u002F","\n    ","{","\n      ","property",";","}","a","comment","number","script","canvas","string","video","const",2,"h2","true",-1,"icon","icon-link","body","0","width","height","\n  faceapi"," video","arrow","=\u003E","nofollow","noopener","noreferrer","_blank","strong","html","meta","style","100","li","dom","variable","\n\n","class-name","nets","loadFromUri","'\u002Fface-detection-cam\u002Fmodels'"," faceapi","\n    faceapi","draw"," resizedDetections","How to implement live facial expression detection on a web browser.","face-api","Face API","frontend-view---file-element","Frontend View - File element","application---the-script","Application - The Script","live-demonstration","Live Demonstration","https:\u002F\u002Fjustadudewhohacks.github.io\u002Fface-api.js\u002Fdocs\u002Fglobals.html","https:\u002F\u002Fwww.researchgate.net\u002Ffigure\u002F68-facial-landmarks_fig1_338048224","div","nuxt-content-highlight","pre","line-numbers","code","name","head","content","title","defer","src","selector","unit"," center","document","startVideo","parameter","err","console"," displaySize"," canvas","https:\u002F\u002Fchivalryytf.me\u002Fface-detection-cam")));